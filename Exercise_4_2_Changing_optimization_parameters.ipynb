{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mihate2903/hot-lesbian-seg/blob/main/Exercise_4_2_Changing_optimization_parameters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 4.2 Changing optimization parameters\n"
      ],
      "metadata": {
        "id": "ApEGsGnec6BZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this exercise, you will use the same titanic dataset from the previous exercises. You can download the dataset from the following link:\n",
        "\n",
        "[titanic_all_numeric.csv](https://drive.google.com/file/d/11nuYS-l3EXCsGJt81y4YTt3oTnFGaB68/view?usp=drive_link)\n",
        "\n",
        "The data is pre-loaded into a pandas DataFrame called `df`. The `predictors` and `target` values are also pre-defined.\n",
        "\n",
        "You'll want the optimization to start from scratch every time you change the learning rate, to give a fair comparison of how each learning rate did in your results. So we have created a function `get_new_model()` that creates an unoptimized model to optimize.\n",
        "\n",
        "It's time to get your hands dirty with optimization. You'll now try optimizing a model at a very low learning rate, a very high learning rate, and a \"just right\" learning rate. You'll want to look at the results after running this exercise, remembering that a low value for the loss function is good."
      ],
      "metadata": {
        "id": "mEOOH6NdV42q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instructions"
      ],
      "metadata": {
        "id": "-AWPd5Wqft_d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Import `SGD` from `tensorflow.keras.optimizers`.\n",
        "* Create a list of learning rates to try optimizing with called `lr_to_test`. The learning rates in it should be `0.000001`, `0.01`, and `1.0`.\n",
        "* Using a `for` loop to iterate over `lr_to_test`:\n",
        "  * Use the `get_new_model()` function to build a new, unoptimized model.\n",
        "  * Create an optimizer called `my_optimizer` using the `SGD()` constructor with keyword argument `learning_rate=lr`.\n",
        "  * Compile your model. Set the optimizer parameter to be the SGD object you created above, and because this is a classification problem, use `'categorical_crossentropy'` for the loss parameter, , and `metrics=['accuracy']` to see the accuracy at the end of each epoch.\n",
        "  * Fit the model using the `predictors` and the `target`."
      ],
      "metadata": {
        "id": "fNotC4abWBqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code"
      ],
      "metadata": {
        "id": "oKx-pAyrlVGO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data and convert the data to NumPy array:"
      ],
      "metadata": {
        "id": "K2uQ5t2BRtpg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dlu9wWcWcy44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e8d4d4f-4cea-4882-cad9-5f7da9dbce23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1757448447.py:9: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df.age_was_missing = df.age_was_missing.replace({True: 1, False: 0})\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load csv file into the dataframe: df\n",
        "df = pd.read_csv(\"titanic_all_numeric.csv\")\n",
        "\n",
        "# Convert the boolean values of the 'age_was_missing' column to integer\n",
        "df.age_was_missing = df.age_was_missing.replace({True: 1, False: 0})\n",
        "\n",
        "# Create predictors NumPy array: predictors\n",
        "predictors = df.drop(['survived'], axis=1).values\n",
        "\n",
        "# Save the number of columns in predictors: n_cols\n",
        "n_cols = predictors.shape[1]\n",
        "\n",
        "# Convert the target to categorical: target\n",
        "target = to_categorical(df['survived'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a neural network for a classification task"
      ],
      "metadata": {
        "id": "9jf6A0pPsATU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "def get_new_model():\n",
        "  # Set up the model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
        "  model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "wkgdNpMmsKmt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimize the model with different learning rate:"
      ],
      "metadata": {
        "id": "u986qJ_NOK1h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ouput should be:\n",
        "\n",
        "Testing model with learning rate: 0.000001\n",
        "\n",
        "28/28 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.4074 - loss: 5.5751   \n",
        "\n",
        "\n",
        "Testing model with learning rate: 0.010000\n",
        "\n",
        "28/28 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.5747 - loss: 3.3378   \n",
        "\n",
        "\n",
        "Testing model with learning rate: 1.000000\n",
        "\n",
        "28/28 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.5404 - loss: 28697.6289\n"
      ],
      "metadata": {
        "id": "ecubSk7GZKKp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sFt5SNHMrCiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the SGD optimizer\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# Create list of learning rates: lr_to_test\n",
        "lr_to_test = [0.00001, 0.01, 1.0]\n",
        "\n",
        "# Loop over learning rates\n",
        "for lr in lr_to_test:\n",
        "    print('\\n\\nTesting model with learning rate: %f\\n'%lr )\n",
        "\n",
        "    # Build new model to test, unaffected by previous models\n",
        "    my_model = get_new_model()\n",
        "\n",
        "    # Create SGD optimizer with specified learning rate: my_optimizer\n",
        "    my_optimizer = SGD(learning_rate=lr)\n",
        "\n",
        "    # Compile the model\n",
        "    my_model.compile(optimizer=my_optimizer,\n",
        "                      loss='categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "    # Fit the model\n",
        "    my_model.fit(predictors, target, epochs=10, batch_size=10, verbose=0)\n",
        "    loss, accuracy = my_model.evaluate(predictors, target, verbose=0)\n",
        "    print(f\"{len(predictors)}/{len(predictors)} - 0s 1ms/step - accuracy: {accuracy:.4f} - loss: {loss:.4f}\")"
      ],
      "metadata": {
        "id": "rdrPE2NrOjS5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ade0603-6031-458c-85ae-b413bd0a2154"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Testing model with learning rate: 0.000010\n",
            "\n",
            "891/891 - 0s 1ms/step - accuracy: 0.6667 - loss: 1.4503\n",
            "\n",
            "\n",
            "Testing model with learning rate: 0.010000\n",
            "\n",
            "891/891 - 0s 1ms/step - accuracy: 0.6330 - loss: 0.6584\n",
            "\n",
            "\n",
            "Testing model with learning rate: 1.000000\n",
            "\n",
            "891/891 - 0s 1ms/step - accuracy: 0.3838 - loss: 0.7940\n"
          ]
        }
      ]
    }
  ]
}